\chapter{Results \& Discussion}

\section{Performance Metrics}
In credit scoring, accuracy is often misleading due to class imbalance. If 90\% of applicants are good payers, a model that simply approves everyone achieves 90\% accuracy but fails completely at risk management.
Therefore, we focus on:
\begin{itemize}
    \item \textbf{Recall (Sensitivity):} The percentage of actual defaulters correctly identified. High recall is critical to avoid financial losses.
    \item \textbf{Precision:} The percentage of predicted defaulters who are actually risky. Low precision leads to rejecting good customers (opportunity cost).
    \item \textbf{F1-Score / ROC-AUC:} Balanced metrics to evaluate the trade-off.
\end{itemize}

Our XGBoost model achieved a Recall of \textbf{89\%} on the test set, significantly outperforming the baseline Logistic Regression model.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{mlflow-experiments-metrics.png}
    \caption{Model Performance Metrics tracked in MLflow}
    \label{fig:metrics}
\end{figure}

\section{XAI Analysis & Transparency}
The API provides not just a score, but an explanation. For a high-risk prediction, the system outputs the top contributing factors.
For example:
\textit{"Score lowered due to: 1) High Debt-to-Income ratio (0.45), 2) Short Employment Length (< 2 years)."}

This transparency empowers loan officers to make informed decisions and communicate clearly with applicants, satisfying regulatory requirements.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{api-test-predict-swagger.png}
    \caption{API Prediction Result with Explanation}
    \label{fig:api-result}
\end{figure}
