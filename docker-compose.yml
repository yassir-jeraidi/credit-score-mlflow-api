services:
  # ==========================================================================
  # PostgreSQL Database (MLflow Backend Store)
  # ==========================================================================
  postgres:
    image: postgres:15-alpine
    container_name: credit-score-postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-mlflow}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-mlflow123}
      POSTGRES_DB: ${POSTGRES_DB:-mlflow}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "pg_isready -U ${POSTGRES_USER:-mlflow} -d ${POSTGRES_DB:-mlflow}",
        ]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - credit-score-network
    restart: unless-stopped

  # ==========================================================================
  # MLflow Tracking Server
  # ==========================================================================
  mlflow:
    image: python:3.11-slim
    container_name: credit-score-mlflow
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      MLFLOW_BACKEND_STORE_URI: postgresql://${POSTGRES_USER:-mlflow}:${POSTGRES_PASSWORD:-mlflow123}@postgres:5432/${POSTGRES_DB:-mlflow}
      MLFLOW_ARTIFACT_ROOT: /mlflow/artifacts
    volumes:
      - mlflow_artifacts:/mlflow/artifacts
    ports:
      - "5001:5001"
    command:
      [
        "bash",
        "-c",
        "apt-get update && apt-get install -y curl && pip install 'mlflow<2.10' psycopg2-binary && mlflow server --backend-store-uri postgresql://mlflow:mlflow123@postgres:5432/mlflow --default-artifact-root /mlflow/artifacts --host 0.0.0.0 --port 5001",
      ]
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -f http://localhost:5001/api/2.0/mlflow/experiments/search?max_results=1 || exit 1",
        ]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 90s
    networks:
      - credit-score-network
    restart: unless-stopped

  # ==========================================================================
  # Credit Score API
  # ==========================================================================
  api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: credit-score-api
    user: root
    depends_on:
      mlflow:
        condition: service_healthy
    environment:
      APP_NAME: Credit Score API
      APP_VERSION: "1.0.0"
      DEBUG: "false"
      HOST: "0.0.0.0"
      PORT: "8000"
      MLFLOW_TRACKING_URI: http://mlflow:5001
      MODEL_NAME: credit-score-model
      MODEL_STAGE: Production
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      POSTGRES_USER: ${POSTGRES_USER:-mlflow}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-mlflow123}
      POSTGRES_DB: ${POSTGRES_DB:-mlflow}
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}

    volumes:
      - .:/app
      - mlflow_artifacts:/mlflow/artifacts
      - credit_data:/app/data
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

    ports:
      - "8000:8000"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - credit-score-network
    restart: unless-stopped

  # ==========================================================================
  # Prometheus Monitoring
  # ==========================================================================
  prometheus:
    image: prom/prometheus:v2.48.0
    container_name: credit-score-prometheus
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    ports:
      - "9090:9090"
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
      - "--web.console.libraries=/usr/share/prometheus/console_libraries"
      - "--web.console.templates=/usr/share/prometheus/consoles"
      - "--web.enable-lifecycle"
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - credit-score-network
    restart: unless-stopped

  # ==========================================================================
  # Next.js UI
  # ==========================================================================
  ui:
    build:
      context: ./ui
      dockerfile: Dockerfile
      args:
        API_BASE_URL: http://api:8000
        NEXT_PUBLIC_API_URL: http://localhost:8000
    container_name: credit-score-ui
    depends_on:
      api:
        condition: service_healthy
    environment:
      API_BASE_URL: http://api:8000
      NEXT_PUBLIC_API_URL: http://localhost:8000
      GOOGLE_GENERATIVE_AI_API_KEY: ${GOOGLE_GENERATIVE_AI_API_KEY}
      SESSION_SECRET: ${SESSION_SECRET:-ensetmlopssecret-version2025}
    ports:
      - "3000:3000"
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:3000"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - credit-score-network
    restart: unless-stopped

  # ==========================================================================
  # Model Training Job (run manually)
  # ==========================================================================
  train:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: credit-score-train
    user: root
    environment:
      MLFLOW_TRACKING_URI: http://mlflow:5001
      GIT_PYTHON_REFRESH: quiet
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      AWS_DEFAULT_REGION: eu-west-3
    volumes:
      - mlflow_artifacts:/mlflow/artifacts
      - credit_data:/app/data
    command: >
      bash -c "
        echo 'Pulling data from DVC...' &&
        dvc pull || echo 'DVC pull skipped or failed, will generate data' &&
        python -m ml.train 
          --mlflow-uri http://mlflow:5001 
          --register 
          --promote
      "
    depends_on:
      mlflow:
        condition: service_healthy
    networks:
      - credit-score-network
    profiles:
      - train

  # ==========================================================================
  # Data Generation Job (run manually)
  # ==========================================================================
  generate-data:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: credit-score-generate-data
    user: root
    environment:
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      AWS_DEFAULT_REGION: eu-west-3
    volumes:
      - credit_data:/app/data
    command: >
      bash -c "
        python -m ml.data_generator --n-samples 50000 &&
        echo 'Data generated successfully' &&
        dvc add data/raw/credit_data.csv &&
        dvc push &&
        echo 'Data pushed to S3'
      "
    networks:
      - credit-score-network
    profiles:
      - generate-data

# ==========================================================================
# Networks
# ==========================================================================
networks:
  credit-score-network:
    driver: bridge

# ==========================================================================
# Volumes
# ==========================================================================
volumes:
  postgres_data:
  mlflow_artifacts:
  prometheus_data:
  credit_data:
